{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import torch\n",
    "import torch_geometric\n",
    "from datasets.BatchWSI import BatchWSI\n",
    "from models.model_graph_mil import *\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "dataroot = './data/TCGA/BRCA/'\n",
    "large_graph_pt = 'TCGA-BH-A0DV-01Z-00-DX1.2F0B5FB3-40F0-4D27-BFAC-390FB9A42B39.pt' # example input\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Data Structure\n",
    "- `N`: number of patches\n",
    "- `M`: number of edges\n",
    "- `centroid`: [N x 2] matrix containing centroids for each patch\n",
    "- `edge_index`: [2 x M] matrix containing edges between patches (connected via adjacent spatial coordinates)\n",
    "- `edge_latent`: [2 x M] matric containing edges between patches (connected via latent space)\n",
    "- `x`: [N x 1024] matrix which uses 1024-dim extracted ResNet features for each iamge patch (features saved for simplicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(centroid=[23049, 2], edge_index=[2, 161343], edge_latent=[2, 161343], x=[23049, 1024])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(os.path.join(dataroot, large_graph_pt))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch Geometric, inference on large graphs is very tractable. Here, adjacency matrices are stacked in a diagonal fashion (creating a giant graph that holds multiple isolated subgraphs), and node and target features are simply concatenated in the node dimension\n",
    "\n",
    "This procedure has some crucial advantages over other batching procedures:\n",
    "\n",
    "- GNN operators that rely on a message passing scheme do not need to be modified since messages still cannot be exchanged between two nodes that belong to different graphs.\n",
    "\n",
    "- There is no computational or memory overhead. For example, this batching procedure works completely without any padding of node or edge features. Note that there is no additional memory overhead for adjacency matrices since they are saved in a sparse fashion holding only non-zero entries, i.e., the edges. \n",
    "- For more details, see the advanced mini-batching FAQ in: https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchWSI(batch=[46098], centroid=[46098, 2], edge_index=[2, 322686], edge_latent=[4, 161343], ptr=[3], x=[46098, 1024])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = BatchWSI.from_data_list([torch.load(os.path.join(dataroot, large_graph_pt)), \n",
    "                                torch.load(os.path.join(dataroot, large_graph_pt))])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference + Backprop using 23K patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchWSI(batch=[23049], centroid=[23049, 2], edge_index=[2, 161343], edge_latent=[2, 161343], ptr=[2], x=[23049, 1024])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = BatchWSI.from_data_list([torch.load(os.path.join(dataroot, large_graph_pt))])\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 1382917\n",
      "Time Elapsed: 0.06325 seconds\n"
     ]
    }
   ],
   "source": [
    "model_dict = {'num_layers': 4, 'edge_agg': 'spatial', 'resample': 0, 'n_classes': 1}\n",
    "model = PatchGCN_Surv(**model_dict).to(device)\n",
    "print(\"Number of Parameters:\", count_parameters(model))\n",
    "\n",
    "### Example Forward Paas + Gradient Backprop\n",
    "start = time.time()\n",
    "out = model(x_path=data)\n",
    "out[0].backward()\n",
    "print('Time Elapsed: %0.5f seconds' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference + Backprop using 92K patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchWSI(batch=[92196], centroid=[92196, 2], edge_index=[2, 645372], edge_latent=[8, 161343], ptr=[5], x=[92196, 1024])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Simulating a very large graph (containing 4 subgraphs of 23K patches each)\n",
    "data = BatchWSI.from_data_list([torch.load(os.path.join(dataroot, large_graph_pt)), \n",
    "                                torch.load(os.path.join(dataroot, large_graph_pt)),\n",
    "                                torch.load(os.path.join(dataroot, large_graph_pt)),\n",
    "                                torch.load(os.path.join(dataroot, large_graph_pt))])\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 1382917\n",
      "Time Elapsed: 0.20629 seconds\n"
     ]
    }
   ],
   "source": [
    "model_dict = {'num_layers': 4, 'edge_agg': 'spatial', 'resample': 0, 'n_classes': 1}\n",
    "model = PatchGCN_Surv(**model_dict).to(device)\n",
    "print(\"Number of Parameters:\", count_parameters(model))\n",
    "\n",
    "### Example Forward Paas + Gradient Backprop\n",
    "start = time.time()\n",
    "out = model(x_path=data)\n",
    "out[0].backward()\n",
    "print('Time Elapsed: %0.5f seconds' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming worst case scenario that every graph has ~100K patches, for a dataset of 1000 WSIs, an epoch would take 3.43 minutes, with 20 epochs taking ~ 1 hour."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
